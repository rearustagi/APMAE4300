{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Rea Rustagi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%precision 16\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da4230082df60378351d372b0269abdf",
     "grade": false,
     "grade_id": "cell-55a02d473f72b71e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Final Project\n",
    "\n",
    "This notebook will provide a brief structure and rubric for presenting your final project.\n",
    "\n",
    "The purpose of the project is 2-fold\n",
    "* To give you an opportunity to work on a problem you are truly interested in (as this is the best way to actually learn something)\n",
    "* To demonstrate to me that you understand the overall workflow of problem solving from problem selection to implementation to discussion\n",
    "\n",
    "You can choose any subject area that interests you as long as there is a computational component to it.  However, please do not reuse projects or homeworks you have done in other classes.  This should be **your** original work.\n",
    "\n",
    "### Structure\n",
    "There are 5 parts for a total of 100 points that provide the overall structure of a mini research project.\n",
    "\n",
    "* Problem Description\n",
    "* Problem Justification\n",
    "* Description of Computational components needed to address problem\n",
    "* Implementation including tests\n",
    "* Discussion of results and future directions\n",
    "\n",
    "For grading purposes, please try to make this notebook entirely self contained.\n",
    "\n",
    "The project is worth about 2 problem sets and should be of comparable length or less (please: I will have 120 of these to read and I am not expecting full papers).  The actual project does not necessarily have to work but in that case you should demonstrate that you understand why it did not work and what steps you would take next to fix it.\n",
    "\n",
    "Have fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff7027fa77c8991162c077d7e1b09a13",
     "grade": false,
     "grade_id": "cell-1f6e387ca20a818b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem Description [20 pts]\n",
    "\n",
    "Briefly describe the general problem you want to solve and the goals you hope to achieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ecee7a74b7e964b9870636e4e51e72b",
     "grade": true,
     "grade_id": "cell-4aaea9b913990b49",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Urban sprawl has widely been identified as a major environmental issue for a host of reasons, and it has been a large contributer to the changing landscape in New Jersey in particular, as suburbs are ubiquitous in this region. Many existing suburbs were created as a result of unsupervised urban expansion, rather than deliberate planning. As a result, many suburban communities were formed in proximity to major highways and established through strip development, which increases auto dependency, fragments rural land, and diminishes community vitality. Automobile commuting contributes greatly to suburban energy use and emissions. Other issues include resource wastage and destructon of biodiversity.\n",
    "\n",
    "However, it is often difficult on a macroscopic scale to determine the scale of urban/suburban expansion. Numerical methods have been identified as helpful tools for quanitfying the extent of urban sprawl in other locations, such as in post-Soviet Russian cities in Poghosyan 2017. In this project, I aim to use Principal Component Analysis (PCA) on LANDSAT 7 images of Central New Jersey from 1999 and 2020 to perform an analysis of changes in land usage during this period.\n",
    "\n",
    "I hope that this analysis will lend itself to a clearer understanding of the scope of urban sprawl in this region, so as to inform policy decisions regarding zoning and residential development, as well as increase awareness of the issue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd8bc0555f58932f0d17988a683a0318",
     "grade": false,
     "grade_id": "cell-9612e7baba9dcec3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem Justification [10 pts]\n",
    "\n",
    "Briefly describe why this problem is important to you,  and, if possible, to anyone else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0fba2a69faf2414275eaa3558663b38b",
     "grade": true,
     "grade_id": "cell-10940ce7dfe177b2",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "I grew up in an area of central New Jersey that was largely rural when my parents settled there in 1992. My town, Hillsborough, has experienced rapid development in the last three decades, with a great deal of agricultural land being developed for various residential projects. A similar transformation has occurred throughout the county and in surrounding counties, as many have settled in the area to take advantage of good school systems and access to both New York City and Philadelphia. So, this problem is particularly important to me because urban sprawl has drastically changed the landscape of my hometown. This is additionally a matter of importance to others interested in the environmental impact of urban sprawl, as defining the scope of the issue is often the first step in developing an effective and holistic plan to mitigate negative effects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d281e2897f8d8315e263311d618ac78c",
     "grade": false,
     "grade_id": "cell-2d624f58d234da74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Numerical Methods [10 pts]\n",
    "\n",
    "Briefly describe the specific approach you will take to solve some concrete aspect of the general problem including the numerical or computational methods you intend to use.  These can include methods we did not discuss in class but provide some reference to the method. You do not need to explain how the methods work, but you should briefly justify your choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d9733ed004d8c13c107b627356de3d8",
     "grade": true,
     "grade_id": "cell-b4c8d6f3b2978895",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "As I previously mentioned, I will be utilizing PCA to perform a visual analysis of the LANDSAT data from 1999 and 2020. PCA is an effective tool for visual data compression, which will reduce confusing natural color images of the aerial landscape into high contrast \"zones.\" Therefore, it will become much easier to visually identify changes that have taken place during the 1999-2020 timeframe. \n",
    "\n",
    "I will be following the approach of Santhosh Kumar's PCA image analysis to additionally explore the fidelity of PCA in information retention. This project explores a step by step PCA implementation, which I will validate with a scikitlearn PCA implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5154234aae51234a4507952521ac4896",
     "grade": false,
     "grade_id": "cell-36d5696306c198ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation [40 pts]\n",
    "\n",
    "Use the Markdown and Code blocks below to implement and document your methods including figures.  Only the first code block will be a grading cell but feel free to add (not copy) cells in this section to organize your work. \n",
    "\n",
    "For at least one routine you code below, you should provide a test block (e.g. that implements `numpy.testing` routines) to validate your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d5c32e87de6de93daaa811c218da220",
     "grade": true,
     "grade_id": "cell-a6a2bd8bddd92cad",
     "locked": false,
     "points": 50,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The inputs for this project are LANDSAT 7 packets taken from https://earthexplorer.usgs.gov/. For our purposes, we will only be extracting 6 bands from the entire data packet. These bands are described as follows:\n",
    "<table width=\"80%\">\n",
    "    <tr align=\"center\"><th>Band</th> <th align=\"center\">Description</th></tr>\n",
    "     <tr align=\"center\"><td>1</td> <td align=\"center\">Blue</td> </tr>\n",
    "     <tr align=\"center\"><td>2</td> <td align=\"center\">Green</td> </tr>\n",
    "     <tr align=\"center\"><td>3</td> <td align=\"center\">Red</td> </tr>\n",
    "     <tr align=\"center\"><td>4</td> <td align=\"center\">Near Infrared</td> </tr>\n",
    "     <tr align=\"center\"><td>5</td> <td align=\"center\">Shortwave Infrared</td> </tr>\n",
    "     <tr align=\"center\"><td>6</td> <td align=\"center\">Thermal</td> </tr>\n",
    "</table>\n",
    "The packets used here were taken from August 1999 and June 2000. First, we will load the band images in as arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# False Color mapping RGB = 5,4,3 for better contrast\n",
    "red1 = Image.open(\"1999band5.jpg\").convert('L')\n",
    "green1 = Image.open(\"1999band4.jpg\").convert('L')\n",
    "blue1 = Image.open(\"1999band3.jpg\").convert('L')\n",
    "\n",
    "red2 = Image.open(\"2020band5.jpg\").convert('L')\n",
    "green2 = Image.open(\"2020band4.jpg\").convert('L')\n",
    "blue2 = Image.open(\"2020band3.jpg\").convert('L')\n",
    "\n",
    "merge1 = Image.merge(\"RGB\", (red1, green1, blue1))\n",
    "merge2 = Image.merge(\"RGB\", (red2, green2, blue2))\n",
    "\n",
    "img1 = np.array(merge1)\n",
    "img2 = np.array(merge2)\n",
    "img_shape1 = img1.shape[:2]\n",
    "img_shape2 = img2.shape[:2]\n",
    "\n",
    "# Landsat 7 has 6 bands given in their GEOTIFF package\n",
    "n_bands = 6\n",
    "\n",
    "NJ_img1999 = np.zeros((img_shape1[0], img_shape1[1], n_bands))\n",
    "NJ_img2020 = np.zeros((img_shape2[0], img_shape2[1], n_bands))\n",
    "\n",
    "# Loading images into array\n",
    "for i in range(n_bands):\n",
    "    NJ_img1999[:,:,i] = cv2.imread('1999band'+str(i+1)+'.jpg',\n",
    "                               cv2.IMREAD_GRAYSCALE)  \n",
    "    NJ_img2020[:,:,i] = cv2.imread('2020band'+str(i+1)+'.jpg',\n",
    "                               cv2.IMREAD_GRAYSCALE)  \n",
    "\n",
    "# Original False Color Images\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
    "fig.suptitle('False Color Images', fontsize=15)\n",
    "ax1.imshow(img1)\n",
    "ax1.set_title('Aug 1999')\n",
    "ax2.imshow(img2)\n",
    "ax2.set_title('Jun 2020')\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better picture of what each band is relaying, we can look at the reflectance of each one. The features in these images include rivers, developed areas, and agricultural land. What we will find is that all the bands are not necessary to give us a picture of the land features. Many features are clearly captured in the first 2-3 bands. This gives us the intuition to use a compression technique to better capture visual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['1999', '2020']\n",
    "rows = ['Band {}'.format(row) for row in range(1, 7)]\n",
    "\n",
    "fig,axes = plt.subplots(6,2,figsize=(15,15))\n",
    "fig.suptitle('Intensities of Bands 1-6', fontsize=20)\n",
    "\n",
    "for ax, col in zip(axes[0], cols):\n",
    "    ax.set_title(col)\n",
    "\n",
    "for ax, row in zip(axes[:,0], rows):\n",
    "    ax.annotate(row, (0, 0.5), xytext=(-45, 0), ha='right', va='center',\n",
    "                size=20, rotation=0, xycoords='axes fraction',\n",
    "                textcoords='offset points')\n",
    "    \n",
    "for i in range(n_bands):\n",
    "    axes[i,0].imshow(NJ_img1999[:,:,i], cmap='gray')\n",
    "    axes[i,0].axis('off')\n",
    "    axes[i,1].imshow(NJ_img2020[:,:,i], cmap='gray')\n",
    "    axes[i,1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will standardize our data, which is currently expressed as a (877, 968, 6) array. We will do this by flattening the array as well as subtracting the mean and then dividing standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NJ_matrix1999 = np.zeros((NJ_img1999[:,:,0].size,n_bands))\n",
    "NJ_matrix2020 = np.zeros((NJ_img2020[:,:,0].size,n_bands))\n",
    "for i in range(n_bands):\n",
    "    \n",
    "    NJ_array1999 = NJ_img1999[:,:,i].flatten()\n",
    "    NJ_stnd_1999 = (NJ_array1999 - NJ_array1999.mean())/NJ_array1999.std()  # Standardize each variable \n",
    "    NJ_matrix1999[:,i] = NJ_stnd_1999\n",
    "\n",
    "    NJ_array2020 = NJ_img2020[:,:,i].flatten()\n",
    "    NJ_stnd_2020 = (NJ_array2020 - NJ_array2020.mean())/NJ_array2020.std()  # Standardize each variable \n",
    "    NJ_matrix2020[:,i] = NJ_stnd_2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two main steps of PCA are computing the covariance matrices and eigenvalues/vectors of this matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covariance Matrix\n",
    "cov1999 = np.cov(NJ_matrix1999.transpose())\n",
    "cov2020 = np.cov(NJ_matrix2020.transpose())\n",
    "\n",
    "# Eigenvalues, eigenvectors\n",
    "evals1999, evecs1999 = np.linalg.eig(cov1999)\n",
    "evals2020, evecs2020 = np.linalg.eig(cov2020)\n",
    "\n",
    "print(\"1999 Image Eigenvalues:\\n\\n\", evals1999,\"\\n\")\n",
    "print(\"2020 Image Eigenvalues:\\n\\n\", evals2020,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.matshow(cov1999, cmap=plt.cm.PuRd)\n",
    "plt.colorbar(img, ticks = [-1, 0, 1], fraction=0.045)\n",
    "for x in range(cov1999.shape[0]):\n",
    "    for y in range(cov1999.shape[1]):\n",
    "        plt.text(x, y, \"%0.2f\" % cov1999[x,y], size=12, color='black', ha=\"center\", va=\"center\")\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to actually compute the principal components. We will then validate this from-scratch implementation against the scikitlearn PCA method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordering Eigenvalues and Eigenvectors\n",
    "order1 = evals1999.argsort()[::-1]\n",
    "evals1999 = evals1999[order1]\n",
    "evecs1999 = evecs1999[:,order1]\n",
    "\n",
    "order2 = evals2020.argsort()[::-1]\n",
    "evals2020 = evals2020[order2]\n",
    "evecs2020 = evecs2020[:,order2]\n",
    "\n",
    "# Projection of standardized data on e-vecs yields Principal Components \n",
    "PC_1999 = np.matmul(NJ_matrix1999, evecs1999)\n",
    "PC_2020 = np.matmul(NJ_matrix2020, evecs2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pca = decomposition.PCA(n_components=3)\n",
    "test_std = StandardScaler().fit_transform(NJ_matrix1999)\n",
    "sk_pca = (pca.fit_transform(test_std) * (-1))[:3]\n",
    "first_3_pc = PC_1999[:,:3][:3]\n",
    "\n",
    "# For clarity, only using first 3 elements of PCA matrices\n",
    "print('My Implementation:')\n",
    "print(first_3_pc)\n",
    "print('---------------------------------------')\n",
    "print('Scikitlearn Implementation:')\n",
    "print(sk_pca)\n",
    "\n",
    "np.testing.assert_allclose(first_3_pc, sk_pca)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does PCA capture the original variance of the input data? We can look at how well the variance is reflected in the principal components. (I used the colors of the year for 1999 and 2020 here!) Clearly, we see that the majority of information is captured in the first 3 components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information Retained by Principal Components\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "axes = fig.add_subplot(2, 1, 1)\n",
    "axes.grid()\n",
    "plt.bar([1,2,3,4,5,6],evals1999/sum(evals1999)*100,align='center',width=0.4,tick_label = ['PC1','PC2','PC3','PC4','PC5','PC6'], color = '#98b4d4')\n",
    "axes.set_ylabel('Variance (%)')\n",
    "plt.title('Information Retention 1999')\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"1999: First three PCs retain \" + str(int(sum(evals1999[:3])/sum(evals1999)*100))+\"% of information\")\n",
    "\n",
    "axes = fig.add_subplot(2, 1, 2)\n",
    "axes.grid()\n",
    "plt.bar([1,2,3,4,5,6],evals2020/sum(evals2020)*100,align='center',width=0.4,tick_label = ['PC1','PC2','PC3','PC4','PC5','PC6'], color = '#34558b')\n",
    "axes.set_ylabel('Variance (%)')\n",
    "plt.title('Information Retention 2020')\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"2020: First three PCs retain \" + str(int(sum(evals2020[:3])/sum(evals2020)*100))+\"% of information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will convert our PCA matrices back into 2-d arrays so that we can see how the reconstructed images compare to the original False Color image from the bands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_2d_1999 = np.zeros((img_shape1[0], img_shape1[1], n_bands))\n",
    "PC_2d_2020 = np.zeros((img_shape2[0], img_shape2[1], n_bands))\n",
    "for i in range(n_bands):\n",
    "    PC_2d_1999[:,:,i] = PC_1999[:,i].reshape(-1, img_shape1[1])\n",
    "    PC_2d_2020[:,:,i] = PC_2020[:,i].reshape(-1, img_shape2[1])\n",
    "\n",
    "PC_2d_Norm_1999 = np.zeros((img_shape1[0], img_shape1[1], n_bands))\n",
    "PC_2d_Norm_2020 = np.zeros((img_shape2[0], img_shape2[1], n_bands))\n",
    "for i in range(n_bands):\n",
    "    PC_2d_Norm_1999[:,:,i] = cv2.normalize(PC_2d_1999[:,:,i], np.zeros(img_shape1), 0, 255, cv2.NORM_MINMAX)\n",
    "    PC_2d_Norm_2020[:,:,i] = cv2.normalize(PC_2d_2020[:,:,i], np.zeros(img_shape2), 0, 255, cv2.NORM_MINMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,2,figsize=(25,23))\n",
    "fig.suptitle('Comparison of Original and PC Composite Images', fontsize=30)\n",
    "\n",
    "axes[0,0].imshow(img1)\n",
    "axes[0,0].axis('off')\n",
    "axes[0,1].imshow(PC_2d_Norm_1999[:,:,:3].astype(int))\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[1,0].imshow(img2)\n",
    "axes[1,0].axis('off')\n",
    "axes[1,1].imshow(PC_2d_Norm_2020[:,:,:3].astype(int))\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "cols = ['False Color Images', 'First 3 PCs Merged']\n",
    "rows = ['1999', '2020']\n",
    "\n",
    "for ax, col in zip(axes[0], cols):\n",
    "    ax.set_title(col, fontsize = 20, fontweight = 'bold')\n",
    "\n",
    "for ax, row in zip(axes[:,0], rows):\n",
    "    ax.annotate(row, (0, 0.5), xytext=(-45, 0), ha='right', va='center',\n",
    "                size=20, rotation=0, xycoords='axes fraction',\n",
    "                textcoords='offset points', fontweight = 'bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72d81eeccf468db34170c31f551bf523",
     "grade": false,
     "grade_id": "cell-be1a75652a24999a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Discussion [10 pts]\n",
    "\n",
    "Discuss the results of your code including\n",
    "* Why do you believe that your numerical results are correct (convergence, test cases etc)?\n",
    "* Did the project work (in your opinion)?\n",
    "* If yes:  what would be the next steps to try\n",
    "* If no:  Explain why your approach did not work and what you would do differently next time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90128503e0adebfe097e21323650f6e3",
     "grade": true,
     "grade_id": "cell-667a14d363ded5f5",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "I think that while the PCA method employed here resolved correctly, the project did not ultimately work because the input images were not zoomed in enough to capture the features in a workable capacity. What I mean by this is that since I was seeking to explore the expansion of urban sprawl in the last 2 decades, I should have used satellite data that captured features at the house and building level, rather than broadly reflecting agricultural land use. However, an important takeaway here is that PCA can be used for a variety of tasks in environmental science, particularly in image processing. Other similar research has used these techniques to quantify damage done by wildfires and reduction of wetlands. The success of these projects is highly contingent on the quality of input data. \n",
    "$\\newline$\n",
    "Next steps could include, given better input data, doing computational visual analysis of the PCA reconstructed images to determine the degree of industrial/residential development. If the reconstructed images, for example, had distinct zones that were color coded, the percentage cover could give an indication of the degree of urban sprawl. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
